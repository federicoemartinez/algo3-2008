\chapter{GRASP}

\section{Introducción}

La idea de la metaheurística GRASP es construir una solución mediante una heurística constructiva
(en la que interviene algún factor de aleatoriedad) y luego refinarla mediante una segunda heurística
de búsqueda local, que halla el óptimo en la vecindad del caso construido inicialmente.

Este procedimiento se repite una cierta cantidad de veces. La idea de fondo es que la heurística
constructiva construye candidatos que son apropiados para empezar, y el factor aleatorio
introduce variantes sobre estos candidatos para explorar al menos varios óptimos locales distintos.
Si no existiera este factor, como la búsqueda local es determinista, se encontraría una única
solución óptima localmente (la que está en la vecindad del único candidato construíble).

Para construir el algoritmo GRASP es necesario por lo tanto introducir un elemento aleatorio
a la heurística constructiva y determinar un criterio de parada apropiado para terminar la
ejecución del proceso ``construcción - refinamiento'' que se lleva a cabo en cada iteración.

\section{Modificaciones a la heuristica constructiva}
\label{modificaciones_constructiva}
Para poder aplicar nuestra heurística constructiva a un procedimiento GRASP, fue necesario 
introducir algún factor de aleatoriedad a la misma.

Consideramos dos formas de hacerlo:
\begin{enumerate}
\item Modificar el criterio de elección del nodo candidato en la inserción:
Se considera un valor $\alpha \in [0,1]$, de modo que en cada paso no se selecciona el de 
grado máximo, sino que se selecciona un $v$ tal que $d(v) \geq \alpha*d_{max}$. Si $\alpha = 1$, 
la elección no es aleatoria, en cambio si $\alpha = 0$, se escoge un candidato totalmente al azar. 
En general, en (0,1), un $\alpha$ más grande implica una lista restringida de candidatos más pequeña.

\item Modificar el criterio de elección de la posición:
Frente a un ``empate'' de posiciones (cuando para un nodo dado a insertar hay dos o más posiciones que 
generan la misma cantidad de cruces), el algoritmo original se queda con la primera visitada. 

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\subfigure[]{
\includegraphics[scale=0.2]{./figuras/grasp/empate1.png}}
\setcounter{subfigure}{1}
\subfigure[]{
\includegraphics[scale=0.2]{./figuras/grasp/empate2.png}}
\subfigure[]{
\includegraphics[scale=0.2]{./figuras/grasp/empate3.png}}
\caption{Cualquiera de las 3 posiciones para $v$ es a priori tan buena como las otras}
\end{figure}

Podemos entonces modificar este factor para que de haber ``empate'' se elija al azar alguna
de las posiciones posibles.
\end{enumerate}

Posteriormente, realizaremos experiencias con el fin de determinar si estas modificaciones 
son útiles, y encontrar qué valor de $\alpha$ es conveniente utilizar.

\section{Determinación de los parametros}
Para nuestro algoritmo basado en GRASP debemos fijar tres parámetros:
\begin{enumerate}
\item criterio de parada
\item $\alpha$ (que determina el tamaño de la lista restringida de candidatos)
\item posición aleatoria (que determina si frente a un empate de posiciones nos quedamos con la primera encontrada o con alguna al azar)
\end{enumerate}

El problema de la parametrización de algoritmos basados en metaheurísticas con factores aleatorios es
muy delicado. No disponemos de las herramientas como para establecer un criterio de parada óptimo, puesto
que la definición de dicho óptimo depende del contexto de uso del algoritmo. Además, el problema tiene
parámetros infinitos: cualquier función propuesta a partir de los resultados de las iteraciones de
las heurísticas constructivas y de búsqueda puede ser un parámetro válido.

Esta dificultad es tal que da lugar a situaciones curiosas en el desarrollo de algoritmos basados en 
metaheurísticas. En el caso de los algoritmos genéticos, donde los parámetros suelen ser pocos, no es
inusual recurrir a un segundo algoritmo genético para optimizar los parámetros del primero.

Dada esta situación no podemos más que razonar de forma heurística para asignar valores a los
parámetros. Al menos será necesario hallar un valor apropiado para el  parámetro $\alpha$ de 
la heurística constructiva, y determinar un criterio de parada cuyo desempeño sea al menos
razonable. A partir de ideas heurísticas, intentaremos validar algunas de nuestras predicciones
mediante experimentación.

\subsection{Criterio de parada}
Como dijimos anteriormente, el criterio de parada está muchas veces determinado por el contexto
de uso del algoritmo. En casos de presentación de datos para su observación por personas, puede
ser necesario que dicha presentación tenga un tiempo de respuesta rápido para evitar la percepción
de lentitud que puede tener el usuario si el algoritmo es lento. En aplicaciones para integración
de componentes electrónicos que se producirán en masa, puede ser aceptable esperar un tiempo
sustancial puesto que ese tiempo resulta pequeño comparado con los tiempos y valores involucrados
en la producción posterior. En el primer caso se utilizaría un criterio de parada por cota temporal
constante (¿ya pasó el tiempo suficiente para impacientar al usuario?), mientras que en el segundo
es probable que el algoritmo corra por tanto tiempo como lo permita el plan del proyecto de producción
(lo cual podría ser, potencialmente, hasta que la persona responsable le indique al programa que
terminó su tiempo de cálculo).

En otros casos se busca simplemente una solución de compromiso - el algoritmo debería tomar
un tiempo relativamente corto y obtener una solución en lo posible óptima, o en su defecto
bastante buena.

Razonando heurísticamente, consideramos que el criterio de parada debe tener en cuenta la 
cantidad de nodos que posee el grafo, ya que esta cantidad influye en la cantidad posible de 
configuraciones y por ende en la cantidad de mejoras que se pueden hacer. Como vimos por ejemplo 
en la búsqueda local, en general se necesitan más iteraciones para mejorar una solución de tamaño
mayor. Por esta razón el primer criterio que proponemos es el de hacer tantas iteraciones como nodos
haya en la partición más grande del grafo.

Un segundo criterio que planteamos varía su cantidad de iteraciones de manera adaptativa. Se toma 
como valor máximo en el número de iteraciones la cantidad de nodos del grafo. Si en un iteración no 
se produce una mejora, se disminuye en 1 la cantidad de iteraciones restantes. Si en cambio se produce 
una mejora, la cantidad máxima de iteraciones se divide por 2. Este criterio utiliza, como el anterior, 
la idea de que más nodos implica mas trabajo para mejorar, pero por otro lado agrega la idea de que no 
es posible mejorar indefinidamete y por tanto la ocurrencia de mejoras disminuye la probabilidad de hallar
más en el futuro.


\subsection{Tamaño de la lista de candidatos}
Para determinar el tamaño de la lista de candidatos de la heurística constructiva proponemos también 
dos opciones:
\begin{itemize}
\item Tomar un $\alpha$ fijo = 0.75: La idea es que un valor demasiado bajo de $\alpha$ equivale a elegir
      un nodo cualquiera en lugar de uno de grado máximo. Como observamos empíricamente que elegir
      uno de grado máximo es apropiado, no es bueno alejarse demasiado de este criterio. Por otro lado,
      un $\alpha$ demasiado grande hace que la heurística sea esencialmente determinista, y por lo tanto
      elimina las ventajas de la aleatoriedad en su implementación. Proponemos $\alpha$ = 0.75 como un
      valor intermedio razonable.
\item Tomar un $\alpha$ adaptativo: En este caso, se parte de un $\alpha$ alto, 0.95, y en cada iteración, si no 
      se produce mejora, se disminuye su valor. De esta manera, la lista de candidatos comienza siendo 
      pequeña, con la esperanza de lograr buenos resultados rápidamente, y en la medida en que no se
      observarn mejoras, se da lugar a soluciones más variadas.
\end{itemize}

\subsection{Posición aleatoria}
En este caso, se consideraron las dos alternativas: tomar una posición aleatoria entre las mejores,
o tomar siempre la primer posición.

\subsection{Experimentos}
Con el fin de observar si alguna configuración de los parametros se comportaba mejor que las demás, 
decidimos aplicar cada posible configuración a distintas instancias del problema.
Decidimos identificar a cada combinación mediante un número, lo cual hicimos de la siguiente manera:
\begin{enumerate}
\item $\alpha$ 0.75, primera posición, parada por maximo de partición
\item $\alpha$ 0.75, posición aleatoria, parada adaptativa
\item $\alpha$ 0.75, posición aleatoria, parada por maximo de partición
\item $\alpha$ 0.75, primera posición, parada adaptativa
\item $\alpha$ adaptativa, primera posición, parada por maximo de partición
\item $\alpha$ adaptativa, posición aleatoria, parada adaptativa
\item $\alpha$ adaptativa, posición aleatoria, parada por maximo de partición
\item $\alpha$ adaptativa, primera posición, parada adaptativa
\end{enumerate}

Esto evita la consideración heurística de que los parámetros son independientes. Asumir esto introduce
un nuevo factor desconocido a la elección de los parámetros, aunque también disminuye la cantidad
de combinaciones a examinar. Tomamos la decisión de limitar los parámetros pero sí evaluar todas
sus combinaciones.

Para efectuar las comparaciones decidimos medir el tiempo que requiere cada heurística y además 
considerar la mejora que se logra a partir de la primera iteración del algoritmos, es decir, dada
la solución inicial con la que comienza el GRASP, cual es la mejora que se obtiene mediante las
iteraciones subsiguientes.

Realizamos las siguientes experiencias:
\begin{itemize}
\item Aplicar la heuristica a grafos densos con entre 30 y 50 nodos en cada partición
\item Aplicar la heuristica a grafos ralos  con entre 50 y 70 nodos en cada partición
\end{itemize}

Como en cada experiencia aplicamos las 8 combinaciones, decidimos dividir los gráficos, dejando en 
uno a los que tienen $\alpha$ fijo (combinaciones 1,2,3,4) y por otro a los que usan un $\alpha$ 
adaptativo (5,6,7,8) ya que de no hacer esto se hace muy difícil visualizar los resultados.

Los resultados de la primer experiencia son los siguientes:
\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\subfigure[]{
\includegraphics[height=6cm]{./graficos/grasp/test2.png}}
\setcounter{subfigure}{1}
\subfigure[]{
\includegraphics[height=6cm]{./graficos/grasp/test22.png}}
\caption{Mejora con respecto a la solución propuesta por la búsqueda local}
\end{figure}

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\subfigure[]{
\includegraphics[height=6cm]{./graficos/grasp/tiempos2.png}}
\setcounter{subfigure}{1}
\subfigure[]{
\includegraphics[height=6cm]{./graficos/grasp/tiempos22.png}}
\caption{Tiempo de ejecución (en segundos)}
\end{figure}


Lo que podemos observar es que si bien no existe uno que se destaque por sobre el resto, en general
2 y 6 obtienen buenos resultados. Esto es interesante si tenemos en cuenta que son métodos 
que utilizan el criterio de parada adapatativo. Con respecto a los tiempos de ejecución, el criterio adaptativo 
suele tener tiempos más bajos. Sin embargo, en los casos donde mejora poco (por ejemplo, para n=41) el método 4 
casi no logró mejoras y como podemos observar su tiempo fue más alto en ese caso que el de los métodos no adaptativos.

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\subfigure[]{
\includegraphics[height=6cm]{./graficos/grasp/crucesP.png}}
\setcounter{subfigure}{1}
\subfigure[]{
\includegraphics[height=6cm]{./graficos/grasp/crucesP2.png}}
\caption{Mejora con respecto a la solución propuesta por la busqueda local}
\end{figure}

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\subfigure[]{
\includegraphics[height=6cm]{./graficos/grasp/tiemposP.png}}
\setcounter{subfigure}{1}
\subfigure[]{
\includegraphics[height=6cm]{./graficos/grasp/tiemposP2.png}}
\caption{Tiempo de ejecución (en segundos)}
\end{figure}

En esta experiencia se nota claramente la diferencia de tiempo entre los métodos adaptativos y el 
resto. Con respecto a la mejora en la cantidad de cruces, en este experimento sí se observa un método 
que se desempeñó mejor: el método número 6. Por otro lado, el método 2, que en la experiencia anterior 
se había comportado bastante bien, no logró destacarse.

Dado que la cantidad de cruces que encuentra cada versión del GRASP se mantuvo muy similar, 
decidimos descartar a las heurísticas que no utilizaban un criterio de parada adaptativo, ya que 
tardaban un tiempo superior sin lograr mejoras importantes.

Decidimos también continuar con la experimentación con las versiones que usan un criterio 
de parada adaptativo. De esta manera tratamos de observar como se comportaban en función 
de la densidad del grafo y de la cantidad de nodos móviles. 

Los resultados que obtuvimos son los siguientes:
\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\subfigure[Cantidad de cruces]{
\includegraphics[height=6.5cm]{./graficos/grasp/AumentosMoviles.png}}
\setcounter{subfigure}{1}
\subfigure[Tiempo (en segundos)]{
\includegraphics[height=6cm]{./graficos/grasp/AumentoMovilesTiempo.png}}
\caption{Cruces y tiempo en función de la cantidad de nodos móviles}
\end{figure}

Nuevamente se mantiene la tendencia a disminuir la cantidad de cruces que encuentra 
la heurística cuando se aumenta el número de nodos móviles. La misma tendencia se observaba
ya en la búsqueda local así como también en la constructiva, haciendo muy probable
su aparición tras la combinación de ambas.
Observamos también que los tiempos son similares, con la excepción de la versión 6, 
que necesitó de tiempos mucho menores para lograr una cantidad de cruces menor o igual que los demás.

Nuestra última experiencia en este apartado consistió en dejar fija la cantidad de nodos e 
ir aumentando la densidad. Dado que nuevamente la cantidad de cruces encontrada fue muy similar, 
y teniendo en cuenta la tendencia que vemos en las experiencias anteriores en las cuales la versión 
6 parecía ser mejor que las demás, decidimos graficar esta vez la diferencia entre la cantidad de 
cruces encontrada por la versión 6 y el resto de las versiones.

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\includegraphics[scale=0.65]{./graficos/grasp/difCrucesM.png}
\caption{Diferencia en la cantidad de cruces encontrada por la versión 6 y el resto ($m$ creciente, 50 nodos en cada partición)}
\end{figure}

Este gráfico muestra de manera clara, en primer lugar, que la cantidad de cruces es muy similar 
entre todas las versiones. En segundo lugar vemos como la versión 6 efectivamente tiende a comportarse 
mejor. Esto se refleja en que al graficar la diferencia entre la cantidad de cruces encontradas por esta versión 
y la cantidad encontrada por las demás, la mayor parte de los puntos son negativos. Ahora, si bien la mayor parte de 
los puntos están por debajo del 0, las diferencias son notablemente pequeñas, lo cual venimos observando desde la primer 
experiencia.

Medimos por último los tiempos de ejecución:

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\includegraphics[scale=0.6]{./graficos/grasp/tiempoM.png}
\caption{Tiempo de ejecución ($m$ creciente, 50 nodos en cada partición)}
\end{figure}

En este gráfico volvemos a observar un buen desempeño de la versión 6, y además vemos como 
el método 8 y 2 se encontraron con un caso que no pudieron mejorar rápidamente y obtuvieron un tiempo muy alto.

\subsection{Conclusiones}

Las experiencias son la viva imagen de la complejidad del problema a atacar. Si bien en teoría los
diferentes criterios y parámetros parecen afectar de forma sustancial los resultados, no se observa
ningún patrón claro en los gráficos, a excepción de la mejora en tiempo que acarrean los criterios
de parada adaptativos por sobre los constantes.

Esencialmente, lo que observamos es que si bien hay diferencias entre las distintas combinaciones 
de parámetros, en general no existe un ganador contundente. No obstante, en ambas experiencias la 
combinación \textit{$\alpha$ adaptativa, posición aleatoria y parada adaptativa} se mostró como una buena 
opción, tanto a nivel de mejora en la cantidad de cruces, como a nivel de tiempo de ejecución.

Creemos que esto tiene bastante sentido, porque el criterio adapatativo, como explicamos antes, se basa
en que si bajó mucho el número de cruces, es de esperarse que sea menos probable seguir mejorando. De esta 
manera, suele dar tiempos mas bajos que un criterio estático.

Por otro lado un $\alpha$ adaptativo trata de usar las mejores soluciones que genera una lista 
restrictiva, ampliándola a medida que esta se va agotando.

Finalmente, elegir la posición de inserción al azar nos brinda en general una familia más amplia 
para un mismo $\alpha$, y de esta manera permite encontrar soluciones que con el criterio de primer 
posición no se encontrarían por quedar fuera del universo alcanzable.

Concluyendo, decidimos tomar estos parámetros para construir nuestro GRASP.


\section{Pseudocódigo}

\begin{algorithm}[H]
\caption{Propone un dibujo mediante la metaheurística GRASP}
\begin{algorithmic}[1]
\STATE solActual $\leftarrow$ construir solución mediante la heurística constructiva y mejorarla mediante la búsqueda local.
\STATE crucesActual $\leftarrow$ cantidad de cruces de la solución propuesta
\STATE iteraciones $\leftarrow$ 0
\STATE maxIteraciones = cantidad de nodos
\STATE $\alpha$ $\leftarrow$ 0.95
\WHILE{iteraciones < maxIteraciones}
\STATE nuevoDibujo $\leftarrow$ construir un dibujo con la heurística constructiva randomizada con $\alpha$ (seleccionando cada vez una posición al azar de entre las mejores), y aplicar búsqueda local
\STATE nuevosCruces $\leftarrow$ cantidad de cruces de nuevoDibujo
\IF{ nuevosCruces $<$ crucesActual}
\STATE solActual $\leftarrow$ nuevoDibujo
\STATE crucesActual $\leftarrow$ nuevosCruces
\STATE maxIteraciones $\leftarrow$ maxIteraciones $/$ 2
\ELSE
\STATE iteraciones $\leftarrow$ iteraciones + 1
\STATE $\alpha$ $\leftarrow$ minimo($\alpha$ - 0.02,0)
\ENDIF
\ENDWHILE
\RETURN solActual
\end{algorithmic}
\end{algorithm} 

\section{Cálculo de complejidad}

Examinemos paso por paso el algoritmo. Lo primero que hacemos es crear una primer solución 
mediante la heurística constructiva y mejorarla con nuestra heurística de búsqueda local. El 
orden de hacer esto es $O(v_{max}^2*m*log(v_{max})*m^2 + Moviles*v_{max}^2 + m*log(fijos_{max})+fijos_{max} + (V_1+V_2+m)))$. 

Contar los cruces de esta solución tiene un costo $O(m*log(v_max))$, pero este costo es absorbido 
por la construcción de la solución inicial.

Luego comenzamos a iterar: cada iteracíón tiene el costo de las heurísticas, más el del conteo de cruces, 
que por lo que vimos hace instantes es en total $O(v_{max}^2*m*log(v_{max})*m^2 + Moviles*v_{max}^2 + m*log(fijos_{max})+fijos_{max} + (V_1+V_2+m))$. 
Esto lo hacemos cada vez que iteramos. En el peor de los casos, nunca logramos hacer ninguna mejora y por lo 
tanto iteramos tantas veces como nodos hay, o sea un total de $O(v_max)$ iteraciones. Luego el costo total de la 
heurística GRASP es:

$$O(v_{max}*(v_{max}^2*m*log(v_{max})*m^2 + Moviles*v_{max}^2 + m*log(fijos_{max})+fijos_{max} + (V_1+V_2+m)))$$

Hay que notar que en un caso más favorable, se lograrán muchas mejoras haciendo que la cantidad de iteraciones
no sea lineal en $v_max$ sino de orden logarítmico.

En función del tamaño de la entrada, sabemos que: 
$$ t = log(P_1)+ \sum_{i=1}^{P_1}{log((p_1)_i)}+ log(P_2)+ \sum_{i=1}^{P_2}{log((p_2)_i)} + log(m_p) + \sum_{i=1}^{m_p}{log((e_i)_0) + log((e_i)_1)} $$
 $$+log(IV_1) + \sum_{i=1}^{IV_1}{log((iv_1)_i)} + log(IV_2) + \sum_{i=1}^{IV_2}{log((iv_2)_i)} + log(m_{iv})+ \sum_{i=1}^{m_{iv}}{log((e'_i)_0) + log((e'_i)_1)} $$ 

Usando esto, más el cálculo hecho para la complejidad de la búsqueda local en función de 
la entrada, podemos ver que el orden es $O(t^6*log(t))$.





\section{Análisis experimental}

\subsection{Casos patológicos}

Para determinar un caso malo para nuestra heurística GRASP, lo que tenemos que buscar es algún 
mal caso de la heurística constructiva que la heurística de búsqueda local no pueda resolver correctamente. 
Con un caso alcanzará puesto que si bien hay un factor de aleatoriedad en la elección de las posiciones
de inserción de los nodos, para un análisis de peor caso es válido suponer que el azar conllevará siempre
la elección de la peor opción posible.

Consideremos entonces el ejemplo de caso malo para la constructiva. Recordemos como era:

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\includegraphics[scale=0.25]{./figuras/constructivas/malCasoConstructivo.png}
\caption{Caso patológico para la heurística constructiva}
\end{figure}

Ahora apliquemos la búsqueda local para ver que resultado obtenemos:

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\subfigure[Partimos del dibujo que produce la heurística constructiva]{
\includegraphics[scale=0.2]{./figuras/constructivas/malCons4.png}}\hspace{0.2in}
\subfigure[Para los nodos fijos, no se puede hacer nada. Al nodo 1 lo cambiamos de posición pero no porque baja la cantidad de cruces, sino porque en caso de empate, la búsqueda local elige la primer posición visitada]{
\includegraphics[scale=0.2]{./figuras/grasp/malGrasp1.png}}\hspace{0.2in}
\subfigure[Al nodo 2 no se lo mueve porque no cambia el número de cruces. El nodo 3 tampoco cambia el número de cruces, pero se lo mueve por lo dicho antes del criterio de elección de posiciones]{
\includegraphics[scale=0.2]{./figuras/grasp/malGrasp2.png}}\hspace{0.2in}
\subfigure[Finalmente se mueve al nodo 4 pero tampoco baja el número de cruces]{
\includegraphics[scale=0.2]{./figuras/grasp/malGrasp3.png}}
\end{figure}

Como el número de cruces no cambió, consideramos que la búsqueda local llegó a un mínimo local y 
no se vuelve a intentar mejorar al dibujo. Sin embargo, como vimos en \ref{mal-caso} el dibujo se 
podía lograr con 0 cruces. Entonces, si consideramos la misma familia que hacía fallar a la heurística 
constructiva, observamos que la búsqueda local no logra mejorar los dibujos que aquella genera, de modo 
que el GRASP fallaría de la misma manera que la heurística constructiva frente a estos casos.

Si bien es cierto que en el peor caso siempre se elige de la misma manera a los nodos a insertar, 
hay que considerar que en la práctica, con un $\alpha$ suficientemente bajo como para dar una lista 
de candidatos adecuadamente grande, es muy poco probable que se repita siempre la peor elección, y 
mas aún si se inserta en una posición aleatoria cada vez. Es por esto que en experimentos prácticos
el comportamiento de las metaheurísticas con componentes aleatorios suele ser favorable.

Para estudiar el comportamiento del GRASP frente a casos que las otras heurísticas resuelven 
muy mal, decidimos aplicarlo a casos de esta familia. Los resultados son los siguientes:

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
% FIXME: este grafico no está!
\includegraphics[height=8cm]{./graficos/casoBorde/malCasoGrasp.png}
\end{figure}
 
Como vemos, si bien hay casos donde no se logra el óptimo, en general se obtiene un resultado 
considerablemente mejor que con las heurísticas originales.

\subsection{Comparativa de heurísticas}

En este apartado realizamos, a modo de experimento final, una comparación entre las distintas heurísticas
desarrolladas a lo largo del trabajo.

Primero realizamos experiencias en casos pequeños, para comparar a las heurísticas contra 
el algoritmo exacto. Estudiamos qué impacto tiene en su performance el aumento del número de nodos, 
de la densidad del grafo y del porcentaje de nodos móviles.


En la primera experiencia medimos tiempos y cruces en función de la cantidad de nodos 
totales del grafo.

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\subfigure[Diferencia en la cantidad de cruces de las heurísticas y el algoritmo exacto]{
\includegraphics[height=6cm]{./graficos/todos/crucesVsExacto.png}}
\setcounter{subfigure}{1}
\subfigure[Porcentaje del tiempo del exacto utilizado por las heurísticas]{
\includegraphics[height=6cm]{./graficos/todos/tiempoVsExacto.png}}
\end{figure}

En la primera gráfica vemos como el GRASP logra obtener una gran cantidad de dibujos 
óptimos, y como en general está siempre muy cerca del valor óptimo. Por otro lado, vemos 
como efectivamente representa una mejora con respecto a la búsqueda local y a la heurística 
constructiva aplicadas individualmente.

Con respecto a los tiempos, lo llamativo es que en casos pequeños los algoritmos heurísticos 
tardan más que el algoritmo exacto, lo cual nos indica que los mismos deberían ser aplicados a 
grafos grandes, donde la diferencia de tiempos se incline a favor de las heurísticas.

Queremos hacer notar, que en algunos casos se observa que la búsqueda local tarda más que la 
constructiva, a pesar de que una ejecución de búsqueda local conlleva una ejecución de la heurística
constructiva para generar el primer candidato. Esto se explica porque las corridas fueron realizadas
por separado y al ser los tiempos de esos casos muy pequeños, las anomalías de medición producen
esas aparentes inconstistencias.

Las siguientes pruebas se realizaron en grafos de 10 nodos en cada partición, aumentando la cantidad de ejes.

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\subfigure[Error relativo de la cantidad de cruces encontrada por las heurísticas]{
\includegraphics[height=6cm]{./graficos/todos/crucesVsExactoM.png}}
\setcounter{subfigure}{1}
\subfigure[Porcentaje de tiempo del algoritmo exacto empleado por las heurísticas]{
\includegraphics[height=6cm]{./graficos/todos/tiempoVsExactoM.png}}
\end{figure}

El gráfico del error relativo nos deja ver nuevamente como, si bien las tres heurísticas 
logran un buen desempeño, el GRASP se comporta destacablemente bien, a tal punto que en todas
las mediciones logró siempre un error relativo menor a 0.025.

Por otro lado, vemos como aún en el caso trivial de 0 ejes, las heurísticas logran mejores 
tiempos. También vemos como a medida que aumenta la densidad del grafo se hace más conveniente 
utilizar las heurísticas, ya que el \textit{backtracking} se muestra muy sensible a un aumento 
en la cantidad de ejes.

A continuación corrimos los algoritmos en grafos de 8 nodos en cada partición, y observamos 
el tiempo necesario así como el desempeño.

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\subfigure[Error relativo de la cantidad de cruces encontrados por las heurísticas]{
\includegraphics[scale=0.6]{./graficos/todos/crucesVsExactoMoviles.png}}
\setcounter{subfigure}{1}
\subfigure[Porcentaje de tiempo del algoritmo exacto usado por las heuristicas]{
\includegraphics[scale=0.6]{./graficos/todos/tiemposVsExactoMoviles.png}}
\end{figure}

Lo que vemos es que a medida que aumenta el número de nodos móviles, peor se torna
la solución que logra la heurística constructiva por sí sola. Creemos que eso se debe a 
que mientras más nodos tienen que ser insertados, más posibilidades hay de que la heurística
tome una decisión incorrecta. Sin embargo, es de destacar como la búsqueda local y el GRASP
mejoran notablemente el desempeño de la constructiva.

En lo que a tiempos se refiere, se ve que el \textit{backtracking} es mucho más sensible 
que las heurísticas a un aumento de la proporción de nodos móviles. También vemos que nuevamente 
se hace preferible usar los algoritmos heurísticos si la proporción es muy alta, aún en casos 
relativamente chicos como los de esta experiencia.

Finalmente, decidimos comparar a las tres heurísticas en casos mas grandes, en los que el exacto 
no puede encontrar la solución correcta en tiempos razonables. Generamos entonces grafos aleatorios 
con una cantidad de nodos en cada partición que va de 30 a 200 y medimos tiempos y cruces.

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\subfigure[Diferencia entre la cantidad de cruces de las heurísticas simples y del GRASP]{
\includegraphics[scale=0.65]{./graficos/todos/crucesGrandes.png}}
\setcounter{subfigure}{1}
\subfigure[Porcentaje de tiempo del GRASP usado por las otras heurísticas]{
\includegraphics[scale=0.65]{./graficos/todos/tiemposGrandes.png}}
\end{figure}

En esta experiencia se marca claramente el compromiso entre calidad de la solución y cantidad de cruces. 
Si bien las heurísticas de búsqueda local y constructiva son mucho más rapidas que el GRASP (lo cual es más
que lógico ya que son parte de cada iteración de este último), también es cierto que dan una solución considerablemente 
peor. Entonces,  si bien el GRASP es más lento que ellas, es una alternativa viable para buscar soluciones 
buenas (sus soluciones son siempre mejores que las de las otras heurísticas) en un tiempo razonable. Una vez
más, qué método es preferible utilizar dependerá del contexto de uso, ya que dependiendo de los casos
podría ser conveniente conformarse con la precisión de las heurísticas simples para otener un mejor rendimiento
temporal.
