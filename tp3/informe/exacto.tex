\chapter{Algoritmo exacto}



\section{Desarrollo}
Un dibujo incremental válido consiste en una permutación de los nodos 
de cada partición que mantenga el orden relativo de los nodos previamente 
fijados. Dados $v_i$ nodos originales en la partición i, se agregan $IV_i$ 
nodos en cada partición. La cantidad posible de soluciones es:
$$IV_1!*\dbinom{IV_1 + v_1}{v_1}*(IV_2!*\dbinom{IV_2 + v_2}{v_2})$$
Esto se debe a que la partición 1 tiene $IV_1 + v_1$ nodos, y por lo 
tanto hay esa cantidad de posiciones. De esas, $v_1$ estarán destinadas a los
nodos existentes, cuyo orden relativo es fijo. Una vez que elegimos sus posiciones, 
el orden entre ellos es fijo. En las $IV_1$ posiciones restantes podemos poner 
cualquier permutación de los nodos nuevos. Luego la cantidad de órdenes válidos
para la partición 1 es: 
$$ IV_1!*\dbinom{IV_1 + v_1}{v_1} $$
Luego, para cada uno de estos órdenes válidos en la partición 1, tenemos (análogamente)
una cantidad equivalente para la partición 2:
$$IV_2!*\dbinom{IV_2 + v_2}{v_2}$$ permutaciones en la segunda partición.
El total de combinaciones es finalmente el producto de las combinaciones de cada
partición, que resulta en la fórmula presentada anteriormente.

Dada la naturaleza exponencial del problema a resolver, decidimos utilizar la técnica de
\textit{backtracking} para formular un algoritmo exacto. Comenzamos por desarrollar un algoritmo
de fuerza bruta que simplemente explora el árbol de combinaciones que va generando progresivamente,
y luego lo fuimos refinando agregando optimizaciones y podas.

El algoritmo de backtracking aprovecha la naturaleza recursiva del problema de dibujo incremental,
agregando progresivamente cada nodo móvil en todas sus posiciones válidas y produciendo así
un nuevo conjunto de nodos fijos que se incrementará con una llamada recursiva. Dado un candidato
inicial con una cantidad de cruces dada, esta situación nos permite realizar una poda sencilla
del árbol de combinaciones. Ocurre que inevitablemente todo dibujo incremental del grafo parte
de un dibujo original cuya cantidad de cruces acota inferiormente la del dibujo incrementado.
Por lo tanto, al construir un candidato para una llamada recursiva, si la cantidad de cruces
en su parte fija supera a la del mejor candidato hallado hasta el momento, no tiene sentido descender
por la rama y puede podarse sin perder soluciones.

Con esta idea, resulta útil proveerse rápidamente de un candidato inicial cuya cantidad de cruces
sea baja, ya que \textit{a priori} permitirá descartar mayor cantidad de ramas por pasarse de su
valor. Con este fin, tiene sentido utilizar alguna solución heurística de las desarrolladas en este
trabajo.

El pseudocódigo del algoritmo resultante es aproximadamente:
\begin{algorithm}[H]
\caption{Halla la solución exacta al problema de dibujo bipartito incremental}
\begin{algorithmic}[1]
\PARAMS{fijo1, fijo2, movil1, movil2, adyacencias}
\STATE construir un candidato abritrario y 
\IF{fijo1 = $\emptyset$ y fijo2 = $\emptyset$}
    \IF{el dibujo obtenido tiene menos cruces que el mejor candidato}
        \STATE reemplazar el mejor candidato por este dibujo
    \ENDIF
\ELSIF{fijo1 $\neq$ $\emptyset$}
    \STATE tomar el primer elemento de movil1
    \FOR{cada posición del elemento en fijo1}
        \STATE poner el elemento en esa posición
        \IF{el dibujo obtenido no tiene más cruces que el mejor candidato}
            \STATE llamar recursivamente
        \ENDIF
        \STATE sacar el elemento de esa posición
    \ENDFOR
\ELSIF{fijo2 $\neq$ $\emptyset$}
    \STATE tomar el primer elemento de movil2
    \FOR{cada posición del elemento en fijo2}
        \STATE poner el elemento en esa posición
        \IF{el dibujo obtenido no tiene más cruces que el mejor candidato}
            \STATE llamar recursivamente
        \ENDIF
        \STATE sacar el elemento de esa posición
    \ENDFOR
\ENDIF
\RETURN el mejor candidato hallado
\end{algorithmic}
\end{algorithm}

De esta manera, el árbol de \textit{backtracking} que tenemos es:
\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\includegraphics[scale=0.9]{./figuras/exacto/arbolbt.png}
\caption{Árbol de \textit{backtracking}}
\end{figure}

El algoritmo lo recorre en orden DFS, cortando aquellas ramas que pueden ser descartadas
inmediatamente sin visitarlas.

\subsection{Implementación eficiente}

Dado que el algoritmo recursivo se ejecutará una vez por cada nodo del árbol de combinaciones,
es importante que su ejecución sea lo más eficiente posible para disminuir el tiempo total
de ejecución.

La primera versión del algoritmo era similar a la de fuerza bruta: recorría el árbol de combinaciones,
y cuando obtenía una permutación completa, construía el dibujo y contaba enteramente sus cruces.
A continuación agregamos la poda simple descripta anteriormente. Sin embargo, resultaba claro
que recalcular los cruces de todo el dibujo para cada hoja del árbol de permutaciones no era
eficiente ya que gran parte de los cálculos eran redundantes entre hojas vecinas del árbol, puesto
que compartían gran parte de las posiciones de los nodos en el dibujo.

Utilizando los métodos descriptos anteriormente, decidimos efectuar los cálculos mediante
una técnica incremental. Constatamos que la iteración que en el pseudocódigo corresponde
a agregar un nodo móvil en todas las posiciones posibles dentro del dibujo fijo de su partición
puede describirse en términos de 3 operaciones: agregar el nodo al final del dibujo, 
permutarlo $n$ veces hacia atrás con su vecino inmediato, y finalmente extraerlo del principio 
del dibujo donde habrá quedado ubicado. Con este procedimiento, un nodo móvil dado
pasa por todas las posiciones posibles dentro del dibujo fijo original.

\begin{figure}[H]
\centering
\setcounter{subfigure}{0}
\includegraphics[scale=0.25]{./figuras/exacto/swaps.png}
\caption{Permutaciones mediante swaps}
\end{figure}

Dado un candidato, la cantidad de cruces que se agregan por agregarle un nuevo nodo al 
final a una partición puede ser calculada mucho más rápidamente que los cruces de todo 
el dibujo. Además, como se vio anteriormente, calcular la cantidad de cruces que resulta
de un \textit{swap} también es eficiente. Esta mejora se incluye en el algoritmo evitando
así recalcular todos los cruces para cada permutación, y en cambio llevando una cuenta temporal
de cruces que se modifica continuamente para reflejar los cruces del candidato que se está
evaluando.

\subsection{Tabulado de resultados}

Aún tras incluir los cálculos incrementales como se describió en el último párrafo, se puede
aprovechar de forma más eficiente aún la realización de ciertos cálculos.
Consideremos un dibujo con dos permutaciones $V = <v_1,v_2,...,v_n>$, $W = <w_1,w_2,...,w_k>$.
La cantidad de cruces puede obtenerse como:
$$Cruces(V,W) = \sum_{i=1}^{k-1}{\sum_{j=i+1}^{k}{crucesEntre(w_i,w_j,V)}}$$

Esto es, dada una permutación de V, los cruces de todo el dibujo, para cualquier
permutación de W, dependen únicamente de los valores de $crucesEntre(w_i, w_j, V)$, función
que calcula los cruces entre dos nodos $w_i$ y $w_j$ para la permutación de V elegida y
suponiendo que $w_i$ está antes de $w_j$ en el dibujo. Esto puede hacerse ya que la cantidad
de cruces que se producen entre los ejes de 2 nodos de una partición depende únicamente de su
orden relativo y de las posiciones dentro de la partición restante.

Por lo tanto, una vez que construimos una permutación de una de las 2 particiones (parte superior
del árbol en el gráfico explicativo del árbol de \textit{backtracking}), podemos tabular los $k^2$
valores de  $crucesEntre()$ necesarios para el cálculo de los cruces de cualquier permutación de
la otra partición: todo el subárbol que pende de una permutación completa de la partición 1 comparte
los mismos valores de $crucesEntre()$. Teniendo esta tabla, el cálculo de cruces del dibujo completo
puede realizarse mediante la suma de los mismos según la fórmula de arriba, lo cual podría agilizar
el conteo de cruces. Cabe destacarse que el llenado de esta tabla tiene un costo no despreciable,
y por tanto es importante realizar pruebas para determinar si las ventajas de realizar este tabulado
no son superadas por el costo de la creación de la tabla. 

Como se verá más adelante, las pruebas mostraron que el uso de esta tabulación mejora significativamente
el rendimiento del algoritmo. En función de esta mejora, podemos observar que los cálculos realizados
con ayuda de la tabla son mucho más rápidos que los que se realizan sin ella. Por lo tanto decidimos
incluir una segunda mejora que consiste en decidir cual de las 2 particiones tiene más permutaciones
posibles, y asignar ésta a la parte inferior del árbol cuya exploración está más optimizada gracias al
uso de la tabla. Antes de esta decisión, se tomaba de forma arbitraria que lo recibido como
``partición 1'' se ubicaba en la parte superior del árbol, puesto que la situación era simétrica y solo
influía el tamaño total del árbol.

Si bien no es posible realizar la misma tabulación para la partición asignada a la parte
superior del árbol (puesto que no disponemos de la ubicación de los nodos en la otra partición
aún), es posible realizar una optimización parcial: si bien no conocemos las posiciones
de \textit{todos} los nodos en la partición vecina, si conocemos la posición de aquellos
que son fijos y por tanto no modifican su orden relativo. Se puede construir una tabla más
pequeña para, nuevamente, agilizar el conteo de cruces en las permutaciones de la
partición de la parte superior.

\subsection{Podas}

Disponiendo de la tabla de cruces entre pares de nodos, pudimos construir una función de poda
más efectiva, mediante una cota inferior más fina para la cantidad mínima de ejes que produce
una rama. Nuevamente, para una permutación dada de $V$, tenemos que:

$$Cruces(V,W) \geq \sum_{i=1}^{k-1}{\sum_{j=i+1}^{k}{min(crucesEntre(w_i,w_j,V),crucesEntre(w_j,w_i,V))}}$$

Como tenemos estos valores tabulados, resulta muy sencillo calcular esta cota y podar en función
del valor obtenido. Esto utiliza el hecho de que dados dos nodos $w_i$, $w_j$ de la partición 2, 
una vez que se los coloque en el dibujo, agregarán una cierta cantidad de cruces (ya sea $crucesEntre(w_i, w_j)$
o $crucesEntre(w_j, w_i)$ dependiendo de su orden relativo). Como disponemos de estos dos valores,
podemos usar el mínimo entre ambos como una cota inferior de los cruces producidos por la dupla
$w_i$, $w_j$ dada la permutación de $V$ tomada.

Una vez que tenemos esta cota inferior, podemos descartar de antemano a aquellas ramas donde el
valor de dicha cota supere la cantidad de cruces del mejor candidato obtenido hasta el momento.
Una vez más, este cálculo redunda en un costo adicional que podría ser contraproducente
en caso de que la poda no lograra eliminar una cantidad significativa de ramas. Nuevamente, es
necesario realizar pruebas para determinar su efectividad. Las mediciones observaron que este
mecanismo de poda es particularmente bueno y elimina partes sustanciales del árbol de permutaciones
sin un costo excesivo (producto, en gran parte, de la disponibilidad de la tabla de cruces
descripta previamente, que aligera mucho el cómputo de la cota).







\section{Pseudocódigo}

\begin{algorithm}[H]
\caption{Resuelve de forma exacta el problema de dibujo incremental de grafos bipartitos}
\begin{algorithmic}[1]
\STATE inicializarParametros
\STATE mejorSolucion $\leftarrow$ construir una solución con la heuristica constructiva
\STATE buscarMejorSolucion()
\RETURN mejorSolucion
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Inicializa variables que va a usar el algoritmo exacto}
\begin{algorithmic}[1]
\STATE determinar cual de las particiones tiene menos permutaciones, llamarla 1, a la otra llamarla 2
\STATE construir índice de posiciones para los nodos que ya están en el dibujo
\STATE construir listas de adyacencia para los nodos de 1 y los fijos de 2
\STATE calcular los cruces del candidato original
\STATE construir la tabla para la partición 1
\IF{no hay móviles en la partición 2}
\STATE construir la tabla para la partición 2
\ENDIF
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Construye todas las particiones que pueden ser solución buscando la mejor (o una de las mejores)}
\begin{algorithmic}[1]
\IF{no hay mas móviles por poner}
\IF{los cruces de la solución que armé son menos que los de la mejor hasta ahora}
    \STATE mejorSolucion $\leftarrow$ solucionActual
\ENDIF
\ELSIF{no hay mas móviles que poner en la partición 1}
    \STATE agregar atrás al primer móvil a la partición (sacarlo de móviles y actualizar índices)
    \STATE cruces $\leftarrow$ cruces + los cruces que me agrega el nuevo nodo
    \WHILE{el nuevo no recorrió todas las posiciones en la partición}
        \IF{cruces + minimoCruces < los cruces del mejor}
            \STATE buscarMejorSolucion()
        \ENDIF
        \STATE intercambiar al nuevo por el nodo que está adelante de él (actualizar posiciones y cruces)
    \ENDWHILE
    \STATE sacar al nodo \COMMENT{quedó adelante de todo en la partición}
    \STATE actualizar posiciones y cruces
\ELSE
    \STATE agregar atrás al primer móvil a la partición (sacarlo de móviles y actualizar índices)
    \STATE cruces $\leftarrow$ cruces + los cruces que me agrega el nuevo nodo
    \WHILE{el nuevo no recorrió todas las posiciones en la partición}
        \IF{cruces + minimoCruces < los cruces del mejor}
            \IF{no quedan más nodos móviles en esta partición}
                \STATE construir tabla para la partición 2
            \ENDIF
            \STATE buscarMejorSolucion()
        \ENDIF
        \STATE intercambiar al nuevo por el nodo que está adelante de él (actualizar posiciones y cruces)
    \ENDWHILE
    \STATE sacar al nodo \COMMENT{quedó adelante de todo en la partición}
    \STATE actualizar posiciones y cruces
\ENDIF
\end{algorithmic}
\end{algorithm}

\begin{itemize}
\item Para construir la tabla 1, se toman todos los nodos de la partición 1 de a pares  $(i,j)$ y se guardan en
una matriz en la posición $(i,j)$ el valor de $CrucesEntre(i,j)$. Para contar los cruces, solo se tienen
en cuenta los nodos fijos de la partición 2. Para construir la tabla 2 se procede análogamente pero se 
toman en cuenta a todos los nodos de la partición 1 (no solo a los fijos) para contar los cruces.
\item minimoCruces utiliza las tablas (la correspondiente a la partición que se está llenando) y realiza la 
cuenta antes descripta para obtener una cota inferior a la cantidad de cruces que se pueden originar agregando
los nodos faltantes en cualquier orden.
\end{itemize}

Las listas de adyacencia parciales, así como los vectores de posiciones parciales se utilizan como
datos de entrada para las funciones incrementales de conteo de cruces. Al ir manteniendo actualizados
estos datos durante la ejecución, evitamos el costo de recalcular índices y adyacencias de todo el grafo
al hacer modificaciones incrementales.






\section{Detalles de implementación}

La implementación del algoritmo fue realizada originalmente en Python por la facilidad
que brinda el lenguaje de alto nivel para hacer pruebas y comparaciones. Se comenzó por
la versión de fuerza bruta y se fue refinando progresivamente el algoritmo agregando
optimizaciones, varias de las cuales fueron descriptas anteriormente. Es importante
destacar que las optimizaciones no fueron hechas de forma aleatoria sino que se realizó
periódicamente un \textit{profiling} del algoritmo para determinar cuales eran las funciones
que insumían más tiempo durante la ejecución, y luego enfocar los esfuerzos de optimización
en ellas. Una vez terminado, el algoritmo completo se reimplementó en C++.

Vale la pena comentar algunos detalles y optimizaciones propios de la implementación.
En primer lugar, se utilizaron \textit{buffers} únicos para almacenar las secuencias
de nodos fijos y móviles que utiliza cada llamada recursiva, que se almacenan
en atributos de la clase $SolucionExacta$ y por tanto son compartidos por todas
las llamadas recursivas. Esto permite ahorrar memoria en el \textit{stack} (que puede
tomar un tamaño considerable) reduciéndolo al tamaño mínimo indispensable. Se evitan
además operaciones de copias innecesarias de estos parámetros. Esto tiene como efecto
secundario la imposibilidad de ejecutar en paralelo dos instancias del algoritmo
en una máquina multiprocesador. Si se pasan todos los parámetros por copia (incluyendo
posiblemente las tablas de valores) la mejora de tiempo de ejecución del algoritmo
en multiprocesadores puede ser esencialmente lineal en la cantidad de CPUs.

Las secuencias en cuestión se implementaron sobre lista doblemente enlazada para 
permitr las operaciones de insertar atrás, \textit{swap} y extraer de adelante en $O(1)$.
Todos los diccionarios se implementaron sobre vectores ya que sus tamaños son lineales
o a lo sumo cuadráticos en $V_1+V_2$ y por lo tanto no tiene sentido ahorrar
memoria en estos aspectos a costa de velocidad cuando el consumo de memoria del algoritmo
estará determinado por el tamaño del \textit{stack}.

Para construir el candidato inicial se utilizó la heurística constructiva que
describimos en \ref{constructivas}.









\section{Cálculo de complejidad}

Antes de correr nuestro algoritmo exacto utilizamos el algoritmo de preprocesamiento descripto en 
\ref{sacoNulos}, lo cual conlleva un costo inicial de $O(V_1+V_2+m)$ donde $V_i$ es la cantidad de 
nodos de la partición $i$ sin filtrar y $m$ la cantidad de ejes del grafo.

En primer lugar el algoritmo inicializa ciertas variables que nos serán de utilidad tales como 
las listas de adyacencia parciales, vectores con posiciones, etc. Todo esto tiene un costo $O(v_1+v_2 + m)$ 
donde $v_i$ es la cantidad de nodos de la partición $i$ ya filtrada. Esto lo podemos acotar por  
$O(v_max + m*log(v_max))$ con $v_max=max(v_1, v_2)$. En esta inicialización se llena la tabla de resultados 
para la primer partición. Lo que calculamos es $crucesEntre(w_i,w_j) \forall w_i,w_j \in v_1$. Esto tiene un 
costo $O(v_{1}*v_{max})$, ya que se efectúan $O(v_{1})$ cálculos y cada cálculo tiene costo $O(v_{max})$ como
se indicó previamente.

 %TODO: completar
Para realizar el estudio de este algoritmo decidimos considerar por separado el llenado de cada 
partición. Como comentamos antes, primero se llena una de las particiones, y a continuación la otra,
pero se efectúan optimizaciones distintas en función del tabulado dependiendo de qué caso se trate. 
Decidimos además ignorar las podas ya que no es posible prever fácilmente si se realizarán o no, por lo
tanto consideraremos (como peor caso) el caso en que se evalúan todas las podas pero éstas no permiten
nunca descartar casos.

Primero observemos el costo que tenemos al pasar por cada nodo del arbol de permutaciones de la primer 
partición. En cada paso lo que hacemos es insertar un elemento al final, y contar cuantos cruces nos agrega, 
lo cual puede hacerse en $O(v_1+ m)$. Esto último no es una cota fina puesto que únicamente se inserta
en cada nivel tantas veces como nodos padre tenga ese nivel, pero utilizamos esta cota para simplificar el
cálculo. Luego intentamos aplicar la poda: este cálculo tiene un costo $O(v_{1}^2)$ ya que tengo que obtener 
la suma de los mínimos de los cruces entre dos elementos y dichos elementos ya están en la tabla. Después 
hacemos otra llamada para ir armando el siguiente nivel (analizada por separado). Una vez que regresamos de 
esa llamada, hacemos un \textit{swap} del nodo con un adyacente y actualizamos los cruces, acción que puede
hacerse en $O(1)$ ya que tenemos los cruces entre ambos tabulados. Una vez que el elemento recorre toda la 
partición hay que sacarlo, lo cual también tiene un costo $O(v_1+ m)$ porque se actualizan nuevamente los cruces.

Entonces recorrer el árbol de llenado de la primer partición tiene un costo:
$$O(nodos * (v_{1}^2 +(v_1+m)))$$

Donde \textit{nodos} es la cantidad de nodos del árbol de \textit{backtracking}. Veamos qué valor
tiene esta variable. Podemos obtener la cantidad de nodos del árbol en función de la cantidad de 
nodos móviles y fijos que tiene la partición involucrada de la siguiente manera:
   \begin{equation}
     tamArbol(moviles,fijos) = \left\{
	       \begin{array}{ll}
		 1      & \mathrm{si\ } moviles = 0 \\
		(fijos+1)*tamArbol(moviles-1,fijos+1) + 1 & \mathrm{si\ } moviles \neq 0 \\
	       \end{array}
	     \right.
   \end{equation}

Esta fórmula no es fácilmente manejable, razón por la cual usaremos una cota. Dado que cada nivel 
tiene más nodos que el nivel anterior (si tengo una permutación de $k$ elementos, al agregar un 
nuevo elemento obtenemos $k + 1$ posibles órdenes), podemos acotar la cantidad de nodos del árbol como:
 $$h*moviles_1!*\dbinom{moviles_1 + fijos_1}{fijos_1}$$

Donde $h$ es la altura del arbol y $moviles_1!*\dbinom{moviles_1 + fijos_1}{fijos_1}$ es la cantidad de hojas.
La altura del árbol es igual a la cantidad de nodos móviles en la partición 1, ya que en cada nivel 
estamos agregando un nodo, mas 1 de la raíz donde no agregamos nada todavía. Luego:

$nodos$ $\leq (moviles_1+1)*moviles_1!*\dbinom{moviles_1 + fijos_1}{fijos_1}$

Luego el orden de completar todas las permutaciones de la primer partición es:

$$O(moviles_1*moviles_1!*\dbinom{moviles_1 + fijos_1}{fijos_1}(v_1+m+v_{1}^2))$$

En cada hoja del árbol de \textit{backtracking} de la primer partición, completamos 
la tabla para la segunda partición. Esto tiene un orden $O(v_2*v_{max})$.

En segunda instancia, completar la segunda partición tiene el mismo costo que completar la primera,
con la salvedad de que en las hojas tenemos un costo $O(v_1+v_2)$ por copiar al mejor dibujo 
(el grafo no se copia, se usa una referencia) en el atributo $mejorDibujo$.
Entonces, completar el árbol de la segunda particion tiene un costo:
$$O((moviles_2+1)*moviles_2!*\dbinom{moviles_2 + fijos_2}{fijos_2}(v_2+m+v_{2}^2) + (v_1+v_2)*moviles_2!*\dbinom{moviles_2 + fijos_2}{fijos_2}(v_2+m+v_{2}^2))$$

Ahora, para cada hoja del árbol de la primer partición, llenamos todo un árbol de la segunda. 
Por lo tanto el costo final es el producto de ambas complejidades, lo que redunda en (luego de sacar algunos factores comunes):

%$ O(moviles_1*moviles_1!*\dbinom{moviles_1 + v_1}{v_1}(v_1+m+v_{1}^2) + moviles_1!*\dbinom{moviles_1 + v_1}{v_1}(v_1+m+v_{1}^2) *(moviles_2*moviles_2!*\dbinom{moviles_2 + fijos_2}{fijos_2}(v_2+m+v_{2}^2) + (v_1+v_2)*moviles_2!*\dbinom{moviles_2 + fijos_2}{fijos_2}(v_2+m+v_{2}^2))+\dbinom{moviles_1 + v_1}{v_1}(v_1+m+v_{1}^2)*v_2*v_{max}+ m*log(v_max))$

$O(moviles_1!*moviles_1!*\dbinom{moviles_1 + fijos_1}{fijos_1}(v_1+m+v_{1}^2)*(moviles_1+ moviles_2!*\dbinom{moviles_2 + fijos_2}{fijos_2}(v_2+m+v_{2}^2)*(moviles_2 + (v_1+v_2)) + v_2*v_{max}) + V_1 + V_2 + m*log(v_max))$ 

Y usando que $moviles_1!*\dbinom{moviles_1 + fijos_1}{fijos_1} = \frac{(moviles_1 + fijos_1)!}{fijos_1!}$:

$O(\frac{(moviles_1 + fijos_1)!}{fijos_1!}(v_1+m+v_{1}^2)*(moviles_1+ \frac{(moviles_1 + fijos_2)!}{fijos_2!}(v_2+m+v_{2}^2)*(moviles_2 + (v_1+v_2)) + v_2*v_{max}) + V_1 + V_2 + m*log(v_max))$ 

En la fórmula vemos que es preferible tomar como primer partición a aquella que tenga una menor 
cantidad de hojas, de esta manera la segunda tabla se construye menos veces y se aprovechan más cálculos.






\section{Análisis experimental}

\subsection{Experiencias realizadas}

A continuación se presentan varias experiencias que fueron realizadas con el
propósito de examinar el comportamiento de los algoritmos, así como de las optimizaciones
que fueron realizadas.

Observamos primero la efectividad de las optimizaciones más importantes
que realizamos sobre el algoritmo de \textit{backtracking} trivial:
\begin{itemize}
\item En primer lugar buscamos mostrar la ventaja de tabular los valores de 
      $crucesEntre$ en memoria y utilizar los métodos incrementales de conteo
      de cruces respecto de la implementación más trivial que consiste en
      volver a contar completamente los cruces de todo el dibujo formado en cada
      hoja del árbol de \textit{backtracking}. Esta prueba fue realizada
      con la implementación en Python de los algoritmos, utilizado CPython 2.5
      para 3 casos grandes del problema, promediando 10 ejecuciones sobre grafos
      del mismo tamaño pero con ejes aleatorios para cada punto. Se consideró
      un grafo ``ralo'' si tiene el 15\% de los ejes del grafo bipartito completo,
      y ``denso'' cuando tiene el 85 \%.
\item En segundo lugar examinamos el comportamiento del algoritmo con tabulado
      de valores según si se utiliza o no la inversión de las particiones (para
      garantizar que la mitad del árbol más grande sea la segunda que se completa).
      Una vez más las comparaciones se hicieron en Python promediando 10 ejecuciones
      sobre instancias grandes del problema.
\item Por último comparamos la eficiencia de los dos criterios de poda: el más
      sencillo que consiste únicamente en eliminar las ramas que se "pasan" del mejor
      candidato obtenido hasta el momento, y la más avanzada que consiste en utilizar
      la cota inferior que se desprende de los valores tabulados previamente. Se
      contabiliza la cantidad de nodos visitados del árbol de \textit{backtracking} como
      porcentaje del tamaño total del árbol. Se utilizó una instancia simétrica de tamaño
      medio y se promediaron 20 ejecuciones para cada punto.
\end{itemize}

A continuación nos enfocamos en la performance del algoritmo completo: 
\begin{itemize}
\item Graficamos primero el tiempo insumido por el algoritmo para resolver un caso de
      tamaño medio variando la cantidad de ejes (que no afecta el tamaño del árbol de
      \textit{backtracking} que depende únicamente de los nodos) pero sí interviene
      en algoritmos auxiliares.
\item Finalmente examinamos el tiempo que insume el algoritmo para resolver instancias
      de diferentes tamaños. Tomamos como variable el tamaño del árbol de \textit{backtracking}
      característico de la instancia en cuestión ya que nos pareció mucho más representativo
      de la dificultad de la instancia que simplemente la cantidad de nodos del grafo.
      Los casos fueron elegidos de forma conveniente para obtener puntos a intervalos regulares,
      pero dado que el tamaño del árbol crece de forma importante cuando se aumentan las
      cantidades de nodos, no fue fácil encontrar valores apropiados que permitan regularidad
      perfecta. Se graficaron tiempos para distintas cantidades de ejes en cada tamaño de 
      grafo. Se utilizó una escala logarítmica en ambos ejes del gráfico para permitir su lectura
      dadas las magnitudes involucradas, y para ofrecer un punto de referencia se acotaron los
      tiempos por una función conveniente.
\end{itemize}

\subsection{Resultados}

\begin{figure}[H]                                                                                     
\centering
\includegraphics[height=11cm]{./graficos/exacto/tiempos_tabulado.png} 
\caption{Tiempos con y sin tabulado de valores}
\end{figure} 

\begin{figure}[H]                                                                                     
\centering
\includegraphics[height=11cm]{./graficos/exacto/tiempos_inversion} 
\caption{Tiempos con y sin inversión de particiones}
\end{figure} 

\begin{figure}[H]                                                                                     
\centering
\includegraphics[height=11cm]{./graficos/exacto/podas.png} 
\caption{Comparación de podas}
\end{figure} 

\begin{figure}[H]                                                                                     
\centering
\includegraphics[height=11cm]{./graficos/exacto/tiempos_densidad.png} 
\caption{Tiempos en función de la densidad del grafo}
\end{figure} 

\begin{figure}[H]                                                                                     
\centering
\includegraphics[height=11cm]{./graficos/exacto/tiempos_cpp.png} 
\caption{Tiempos en función del tamaño del árbol de \textit{backtracking}}
\end{figure} 


\section{Discusión}

Los gráficos iniciales son bastante ilustrativos de las mejoras realizadas al algoritmo.
Resulta claro que tabular los valores de la función $crucesEntre$ y utilizar conteos
incrementales de los cruces redunda en un rendimiento superior del algoritmo, que insume
entre 5 y 10 veces menos tiempo para resolver los casos que el algoritmo de fuerza bruta
o backtracking trivial. Observamos también la diferencia que existe cuando el grafo
es asimétrico en caso favorable y desfavorable (que corresponden a que la partición
que se ubica primero en el árbol de \textit{backtracking} es la que tiene más permutaciones
o no). De todas maneras, en ambos casos el rendimiento fue mejor que el del algoritmo de
fuerza bruta mostrando que el \textit{overhead} de mantenimiento de tablas no niega los
beneficios de tener los valores precalculados.

A continuación vemos la diferencia de tiempo sustancial que ocurre al invertir las particiones
para que la que tiene menos permutaciones siempre se complete primero. El gráfico anterior
sugería esto al comparar los casos favorable y desfavorable de instancias asimétrica. Esta
optimización sencilla reduce a todos los casos asimétricos a la situación favorable y de
ello se desprenden mejoras significativas de performance. Si bien no se aprecia en este gráfico,
estas mejoras son mayores mientras más asimétrico es el grafo (ya que en general el algoritmo
de la primera mitad del árbol es bastante más lento que el de la segunda mitad, como se discutió
antes).

En el tercer gráfico se observa la eficiencia de las podas. Puede observarse que ambas podas
tienen un rendimiento muy razonable, logrando en cualquier caso podas de al menos 85\% del árbol
completo de \textit{backtracking}. Sin embargo, la poda más sofisticada no solo tiene un comportamiento
más constante (la sencilla poda cada vez menos según se incrementa la densidad del grafo), sino que
además sus valores son mucho mejores, no podando nunca menos del 98\% del árbol. Esta poda por
sí sola mejora el rendimiento del algoritmo en 2 órdenes de magnitud, lo cual representa una mejora
importante.

Los últimos dos gráficos refieren al rendimiento de la implementación en C++. Rápidamente se observa
que la densidad del grafo es un factor no despreciable en el tiempo de ejecución del algoritmo.
Esto se debe a que las funciones de conteo de cruces insumen un tiempo que depende esencialmente de
la cantidad de ejes del grafo, y el mayor tiempo insumido por las invocaciones a estas funciones
se aprecia claramente en el rendimiento global del algoritmo.

Por último observamos el tiempo de ejecución global del algoritmo. Este gráfico se aproxima
bastante a lo que uno podría esperar: el tiempo de ejecución del algoritmo está en relación
directa con el tamaño del árbol de \textit{backtracking}. Las irregularidades en la curva se
deben a que, a fines de elegir valores uniformemente espaciados del tamaño del árbol, debieron
usarse intermitentemente instancias simétricas y asimétricas que como vimos anteriormente tienen
tiempos de ejecución característicos diferentes. Proponemos una función que acota el tiempo
de ejecución del algoritmo: $0.004 * \sqrt(tam)$ donde $tam$ es el tamaño del árbol a examinar.
La constante puede variar dependiendo de la computadora que se use y las optimizaciones del
compilador - el valor propuesto corresponde a G++ 4.3 con símbolos de \textit{debugging} en
un Pentium IV 2.8. El uso del flag -O3 de G++ produce un reducción por un factor de aproximadamente
tres en los tiempos insumidos.

Si bien la tendencia de las curvas nos permite intuir que la cota puede no ser suficiente
para instancias muy grandes, si puede dar una idea razonable del tiempo que será necesario
darle al algoritmo para terminar, y en todo caso es de esperarse que la relación entre el tamaño
del árbol y el tiempo insumido sea a lo sumo lineal.
